{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f726a48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Api keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7ea03",
   "metadata": {},
   "source": [
    "## Utilities Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ee8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_response(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2726f3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc3f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee54e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name = \"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4bb883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here are the top 5 places in India:\\n\\n1. Taj Mahal\\n2. Golden Temple\\n3. Varanasi\\n4. Goa\\n5. Darjeeling' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 25, 'total_tokens': 62, 'completion_time': 0.030833333, 'prompt_time': 0.003708732, 'queue_time': 0.232988266, 'total_time': 0.034542065}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-0ac498e8-11e0-484d-9543-e8db868f7842-0' usage_metadata={'input_tokens': 25, 'output_tokens': 37, 'total_tokens': 62}\n",
      "****************************************************************************************************\n",
      "Here are the top 5 places in India:\n",
      "\n",
      "1. Taj Mahal\n",
      "2. Golden Temple\n",
      "3. Varanasi\n",
      "4. Goa\n",
      "5. Darjeeling\n",
      "****************************************************************************************************\n",
      "Here are the top 5 places in India:\n",
      "\n",
      "1. Taj Mahal\n",
      "2. Golden Temple\n",
      "3. Varanasi\n",
      "4. Goa\n",
      "5. Darjeeling\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What are top 5 places in India ? Only return the list of places\")\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "print(result.content)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d066a",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27fe59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method -1\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62176bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Capital of India:**\\nNew Delhi\\n\\n**Top 5 places to visit in Uttar Pradesh:**\\n1. Taj Mahal\\n2. Agra Fort\\n3. Fatehpur Sikri\\n4. Varanasi\\n5. Mathura' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 43, 'total_tokens': 95, 'completion_time': 0.043333333, 'prompt_time': 0.008397293, 'queue_time': 0.363074986, 'total_time': 0.051730626}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-43445c81-aac0-45b8-a6c9-245845833dc8-0' usage_metadata={'input_tokens': 43, 'output_tokens': 52, 'total_tokens': 95}\n",
      "****************************************************************************************************\n",
      "**Capital of India:**\n",
      "New Delhi\n",
      "\n",
      "**Top 5 places to visit in Uttar Pradesh:**\n",
      "1. Taj Mahal\n",
      "2. Agra Fort\n",
      "3. Fatehpur Sikri\n",
      "4. Varanasi\n",
      "5. Mathura\n"
     ]
    }
   ],
   "source": [
    "## Method - 1\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['country','state'],\n",
    "    template=\"\"\"\n",
    "    What is the capital of {country}. Only return the capital name.\n",
    "    Top 5 places to visit in {state}. Only return the list of places.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"country\":\"India\", \"state\": \"Uttar Pradesh\"})\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e23e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Capital of India:** New Delhi\\n\\n**Top 5 places to visit in Uttar Pradesh:**\\n\\n1. Taj Mahal\\n2. Varanasi\\n3. Agra\\n4. Mathura\\n5. Lucknow' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 43, 'total_tokens': 90, 'completion_time': 0.039166667, 'prompt_time': 0.00604614, 'queue_time': 0.232413769, 'total_time': 0.045212807}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-57d5a24f-2555-409e-a0a8-f61e31a4d6db-0' usage_metadata={'input_tokens': 43, 'output_tokens': 47, 'total_tokens': 90}\n",
      "****************************************************************************************************\n",
      "**Capital of India:** New Delhi\n",
      "\n",
      "**Top 5 places to visit in Uttar Pradesh:**\n",
      "\n",
      "1. Taj Mahal\n",
      "2. Varanasi\n",
      "3. Agra\n",
      "4. Mathura\n",
      "5. Lucknow\n"
     ]
    }
   ],
   "source": [
    "## Method - 2\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    What is the capital of {country}. Only return the capital name.\n",
    "    Top 5 places to visit in {state}. Only return the list of places.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"country\":\"India\", \"state\": \"Uttar Pradesh\"})\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fca54",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda5c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='New Delhi\\n\\n1. Taj Mahal\\n2. Agra Fort\\n3. Fatehpur Sikri\\n4. Varanasi\\n5. Mathura' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 53, 'total_tokens': 87, 'completion_time': 0.028333333, 'prompt_time': 0.010394438, 'queue_time': 0.35263418, 'total_time': 0.038727771}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'stop', 'logprobs': None} id='run-0e99b19a-8740-42db-af6c-e56494fe7292-0' usage_metadata={'input_tokens': 53, 'output_tokens': 34, 'total_tokens': 87}\n",
      "****************************************************************************************************\n",
      "New Delhi\n",
      "\n",
      "1. Taj Mahal\n",
      "2. Agra Fort\n",
      "3. Fatehpur Sikri\n",
      "4. Varanasi\n",
      "5. Mathura\n"
     ]
    }
   ],
   "source": [
    "## Method -1\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "user_template = \"\"\"\n",
    "What is the capital of {country}. Only return the capital name.\n",
    "    Top 5 places to visit in {state}. Only return the list of places.\n",
    "\"\"\"\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a helpful assitant\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        ('system', system_template),\n",
    "        ('user', user_template)\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"country\":\"India\", \"state\": \"Uttar Pradesh\"})\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e04362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country', 'state'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nYou are a helpful assitant\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country', 'state'], input_types={}, partial_variables={}, template='\\nWhat is the capital of {country}. Only return the capital name.\\n    Top 5 places to visit in {state}. Only return the list of places.\\n'), additional_kwargs={})]\n",
      "----------------------------------------\n",
      "content='New Delhi\\n\\n1. Taj Mahal\\n2. Agra Fort\\n3. Fatehpur Sikri\\n4. Varanasi\\n5. Lucknow' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 53, 'total_tokens': 87, 'completion_time': 0.028333333, 'prompt_time': 0.007106226, 'queue_time': 0.233489252, 'total_time': 0.035439559}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-afe31714-03fe-4c80-a584-d7285a5db565-0' usage_metadata={'input_tokens': 53, 'output_tokens': 34, 'total_tokens': 87}\n",
      "****************************************************************************************************\n",
      "New Delhi\n",
      "\n",
      "1. Taj Mahal\n",
      "2. Agra Fort\n",
      "3. Fatehpur Sikri\n",
      "4. Varanasi\n",
      "5. Lucknow\n"
     ]
    }
   ],
   "source": [
    "## Method -2\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "user_template = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "What is the capital of {country}. Only return the capital name.\n",
    "    Top 5 places to visit in {state}. Only return the list of places.\n",
    "\"\"\")\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assitant\n",
    "\"\"\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        system_template,\n",
    "        user_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"country\":\"India\", \"state\": \"Uttar Pradesh\"})\n",
    "\n",
    "print(prompt)\n",
    "print(\"--\"*20)\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02835c54",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9909b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f91b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29850/962195712.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm = llm, prompt = prompt)\n",
      "/tmp/ipykernel_29850/962195712.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run({\"country\": \"India\", \"state\": \"Kerala\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country', 'state'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country', 'state'], input_types={}, partial_variables={}, template='\\n    You are helpful assistant.\\n    What is the capital of {country}. Only return the capital name.\\n    Top 5 places to visit in {state}. Only return the list of places.\\n    '), additional_kwargs={})]\n",
      "****************************************************************************************************\n",
      "**Capital of India:** New Delhi\n",
      "\n",
      "**Top 5 places to visit in Kerala:**\n",
      "\n",
      "1. Alleppey\n",
      "2. Munnar\n",
      "3. Periyar National Park\n",
      "4. Fort Kochi\n",
      "5. Wayanad\n",
      "****************************************************************************************************\n",
      "**Capital of India:** New Delhi\n",
      "\n",
      "**Top 5 places to visit in Kerala:**\n",
      "\n",
      "1. Alleppey\n",
      "2. Munnar\n",
      "3. Periyar National Park\n",
      "4. Fort Kochi\n",
      "5. Wayanad\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    You are helpful assistant.\n",
    "    What is the capital of {country}. Only return the capital name.\n",
    "    Top 5 places to visit in {state}. Only return the list of places.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt = prompt)\n",
    "result = chain.run({\"country\": \"India\", \"state\": \"Kerala\"})\n",
    "\n",
    "print(prompt)\n",
    "print(\"*\"* 100)\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367bcbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Capital of India:**\\nNew Delhi\\n\\n**Top 5 places to visit in Kerala:**\\n1. Alleppey\\n2. Munnar\\n3. Kochi\\n4. Periyar National Park\\n5. Wayanad' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 48, 'total_tokens': 99, 'completion_time': 0.0425, 'prompt_time': 0.006336013, 'queue_time': 0.233799006, 'total_time': 0.048836013}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-b891a451-e4f5-4150-a2e7-eafd5d841f06-0' usage_metadata={'input_tokens': 48, 'output_tokens': 51, 'total_tokens': 99}\n",
      "****************************************************************************************************\n",
      "**Capital of India:**\n",
      "New Delhi\n",
      "\n",
      "**Top 5 places to visit in Kerala:**\n",
      "1. Alleppey\n",
      "2. Munnar\n",
      "3. Kochi\n",
      "4. Periyar National Park\n",
      "5. Wayanad\n"
     ]
    }
   ],
   "source": [
    "## Method - 2\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"country\": \"India\", \"state\": \"Kerala\"})\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f698b7",
   "metadata": {},
   "source": [
    "## Combine multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9900f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='New Delhi' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 32, 'total_tokens': 35, 'completion_time': 0.0025, 'prompt_time': 0.00617825, 'queue_time': 0.23694805900000002, 'total_time': 0.00867825}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-6f973d04-baaf-410a-aacc-4980d4aeefb4-0' usage_metadata={'input_tokens': 32, 'output_tokens': 3, 'total_tokens': 35}\n",
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                    You are helpful assitant.\n",
    "                                          What is the capital of {country}. Only return the capital name.\n",
    "                    \"\"\")\n",
    "\n",
    "chain1 = prompt | llm\n",
    "result = chain1.invoke({\"country\":\"India\"})\n",
    "print(result)\n",
    "\n",
    "capital = clean_response(result.content)\n",
    "print(capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01c97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here are the top 5 places to visit in New Delhi:\\n\\n1. Red Fort\\n2. Qutub Minar\\n3. India Gate\\n4. Akshardham Temple\\n5. Humayun's Tomb\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 39, 'total_tokens': 86, 'completion_time': 0.039166667, 'prompt_time': 0.005475904, 'queue_time': 0.236293425, 'total_time': 0.044642571}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-d3ed93bb-f2d6-4ddb-b743-82733ada4216-0' usage_metadata={'input_tokens': 39, 'output_tokens': 47, 'total_tokens': 86}\n",
      "Here are the top 5 places to visit in New Delhi:\n",
      "\n",
      "1. Red Fort\n",
      "2. Qutub Minar\n",
      "3. India Gate\n",
      "4. Akshardham Temple\n",
      "5. Humayun's Tomb\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                    You are helpful assitant.\n",
    "                    What are the top 5 places to visit in {capital}. Only return the list of places.\n",
    "                    \"\"\")\n",
    "\n",
    "chain2 = prompt | llm\n",
    "result = chain2.invoke({\"capital\":capital})\n",
    "print(result)\n",
    "\n",
    "formatted_res = clean_response(result.content)\n",
    "print(formatted_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb8269b",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ddd2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Below are the list of students\n",
    "\n",
    "1. Rohit (age : 20)\n",
    "3. Virat (age : 25)\n",
    "4. Rishabh (age : 21)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3659690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are helpful assitant.\n",
    "Can you please extract the name and age of student from {text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e55db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "students=[Student(name='Rohit', age=20), Student(name='Virat', age=25), Student(name='Rishabh', age=21)]\n",
      "****************************************************************************************************\n",
      "[Student(name='Rohit', age=20), Student(name='Virat', age=25), Student(name='Rishabh', age=21)]\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'students': [{'name': 'Rohit', 'age': 20},\n",
       "  {'name': 'Virat', 'age': 25},\n",
       "  {'name': 'Rishabh', 'age': 21}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Method - 1\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Student(BaseModel):\n",
    "    name : str = Field(description=\"Student name\")\n",
    "    age : int | None = Field(description=\"Age of student\")\n",
    "\n",
    "class Students(BaseModel):\n",
    "    students : List[Student] = \"list of students\"\n",
    "\n",
    "llm_with_parser = prompt | llm.with_structured_output(Students)\n",
    "result = llm_with_parser.invoke({\"text\": text})\n",
    "\n",
    "print(result)\n",
    "print(\"*\"* 100)\n",
    "print(result.students)\n",
    "## model_dump is used to convert the into dict\n",
    "print(\"*\"* 100)\n",
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc4353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Rohit', 'age': 20}, {'name': 'Virat', 'age': 25}, {'name': 'Rishabh', 'age': 21}]\n"
     ]
    }
   ],
   "source": [
    "## Method - 2\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are helpful assitant.\n",
    "Can you please extract the name and age of student from {text}.\n",
    "Provide the result in valid json format.\n",
    "\"\"\")\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({\"text\" : text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db619be7",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466e0fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_qjrz', 'function': {'arguments': '{\"city\":\"Noida\"}', 'name': 'get_weather'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 931, 'total_tokens': 1006, 'completion_time': 0.0625, 'prompt_time': 0.130414375, 'queue_time': 0.3710391820000001, 'total_time': 0.192914375}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-68f79e4c-f250-4ff5-bde0-79005e170153-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'Noida'}, 'id': 'call_qjrz', 'type': 'tool_call'}] usage_metadata={'input_tokens': 931, 'output_tokens': 75, 'total_tokens': 1006}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from typing_extensions import Optional, Annotated\n",
    "\n",
    "@tool\n",
    "def get_weather(city : Annotated[str, \"city name\"]):\n",
    "    \"\"\"\n",
    "    This function is used to get the weather of city\n",
    "    \"\"\"\n",
    "    return \"shinny\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are helpful assistant.\n",
    "Can you please provide the current temparature of {city}                                        \n",
    "\"\"\")\n",
    "\n",
    "llm_with_tools = prompt | llm.bind_tools([get_weather])\n",
    "result = llm_with_tools.invoke({\"city\": \"Noida?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8285ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': 'Noida'},\n",
       "  'id': 'call_qjrz',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e29f669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"get_weather({'city': 'Noida'})\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{result.tool_calls[0]['name']}({result.tool_calls[0]['args']})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d80f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29850/2122011520.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  get_weather({'city': 'Noida'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shinny'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather({'city': 'Noida'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "320a0e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shinny'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(f\"{result.tool_calls[0]['name']}({result.tool_calls[0]['args']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cc2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
